{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a281d757-f6b9-426a-b251-13430119a3e4",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "- About competition\n",
    "\n",
    "The goal of this competition is to predict if a person has any of three medical conditions. You are being asked to predict if the person has one or more of any of the three medical conditions (Class 1), or none of the three medical conditions (Class 0). You will create a model trained on measurements of health characteristics.\n",
    "To determine if someone has these medical conditions requires a long and intrusive process to collect information from patients. With predictive models, we can shorten this process and keep patient details private by collecting key characteristics relative to the conditions, then encoding these characteristics.\n",
    "Your work will help researchers discover the relationship between measurements of certain characteristics and potential patient conditions.\n",
    "https://www.kaggle.com/competitions/icr-identify-age-related-conditions/data\n",
    "\n",
    "- Data\n",
    "\n",
    "The competition data comprises over fifty anonymized health characteristics linked to three age-related conditions. Your goal is to predict whether a subject has or has not been diagnosed with one of these conditions -- a binary classification problem.\n",
    "\n",
    "train.csv - The training set.\n",
    "Id Unique identifier for each observation.\n",
    "AB-GL Fifty-six anonymized health characteristics. All are numeric except for EJ, which is categorical.\n",
    "Class A binary target: 1 indicates the subject has been diagnosed with one of the three conditions, 0 indicates they have not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38466216-ddda-4598-8326-6e88e2aec4b8",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfbc01a2-b6e2-45fe-b97e-4ba2853cb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "\n",
    "# from sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f45548-ea53-4b33-9eed-a6672d2d10be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 58)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv('data/train.csv')\n",
    "df.replace(['A', 'B'], [0,1], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1ffdc4-fd54-423c-bdb2-ead4ce9623ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Class', 'Id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# define X\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# define Y\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4957\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4809\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4811\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4818\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4819\u001b[0m ):\n\u001b[0;32m   4820\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4821\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4822\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4955\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4956\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4963\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4964\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4965\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6661\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6661\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6662\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Class', 'Id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# define X\n",
    "X = df.drop(columns=['Class', 'Id'])\n",
    "print(X.shape)\n",
    "\n",
    "# define Y\n",
    "y = df['Class']\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b03f42-84df-49a0-ade8-f6993ad093b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    509\n",
       "1    108\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4fb61f-b0c6-4f5c-a8b6-0dbe5a3e2b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 617 entries, 0 to 616\n",
      "Data columns (total 55 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AB      617 non-null    float64\n",
      " 1   AF      617 non-null    float64\n",
      " 2   AH      617 non-null    float64\n",
      " 3   AM      617 non-null    float64\n",
      " 4   AR      617 non-null    float64\n",
      " 5   AX      617 non-null    float64\n",
      " 6   AY      617 non-null    float64\n",
      " 7   AZ      617 non-null    float64\n",
      " 8   BC      617 non-null    float64\n",
      " 9   BD      617 non-null    float64\n",
      " 10  BN      617 non-null    float64\n",
      " 11  BP      617 non-null    float64\n",
      " 12  BQ      557 non-null    float64\n",
      " 13  BR      617 non-null    float64\n",
      " 14  BZ      617 non-null    float64\n",
      " 15  CB      615 non-null    float64\n",
      " 16  CC      614 non-null    float64\n",
      " 17  CD      617 non-null    float64\n",
      " 18  CF      617 non-null    float64\n",
      " 19  CH      617 non-null    float64\n",
      " 20  CL      617 non-null    float64\n",
      " 21  CR      617 non-null    float64\n",
      " 22  CS      617 non-null    float64\n",
      " 23  CU      617 non-null    float64\n",
      " 24  CW      617 non-null    float64\n",
      " 25  DA      617 non-null    float64\n",
      " 26  DE      617 non-null    float64\n",
      " 27  DF      617 non-null    float64\n",
      " 28  DH      617 non-null    float64\n",
      " 29  DI      617 non-null    float64\n",
      " 30  DL      617 non-null    float64\n",
      " 31  DN      617 non-null    float64\n",
      " 32  DU      616 non-null    float64\n",
      " 33  DV      617 non-null    float64\n",
      " 34  DY      617 non-null    float64\n",
      " 35  EB      617 non-null    float64\n",
      " 36  EE      617 non-null    float64\n",
      " 37  EG      617 non-null    float64\n",
      " 38  EH      617 non-null    float64\n",
      " 39  EJ      617 non-null    int64  \n",
      " 40  EP      617 non-null    float64\n",
      " 41  EU      617 non-null    float64\n",
      " 42  FC      616 non-null    float64\n",
      " 43  FD      617 non-null    float64\n",
      " 44  FE      617 non-null    float64\n",
      " 45  FI      617 non-null    float64\n",
      " 46  FL      616 non-null    float64\n",
      " 47  FR      617 non-null    float64\n",
      " 48  FS      615 non-null    float64\n",
      " 49  GB      617 non-null    float64\n",
      " 50  GE      617 non-null    float64\n",
      " 51  GF      617 non-null    float64\n",
      " 52  GH      617 non-null    float64\n",
      " 53  GI      617 non-null    float64\n",
      " 54  GL      616 non-null    float64\n",
      "dtypes: float64(54), int64(1)\n",
      "memory usage: 265.2 KB\n"
     ]
    }
   ],
   "source": [
    "# find NaNs\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09cfd4-eb2d-4bbd-b090-a52765d8adb2",
   "metadata": {},
   "source": [
    "# Assess models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b033ec90-7e38-42bc-8aff-081a6b104b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn modules\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# scalers\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "scalers = [\n",
    "    StandardScaler(),\n",
    "    MinMaxScaler(),\n",
    "    MaxAbsScaler(),\n",
    "]\n",
    "\n",
    "# import models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    HistGradientBoostingClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    xgb.XGBClassifier(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46183560-e1c5-48df-98e6-d05362e38122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pipeline(scaler, model):\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),  # Impute missing values\n",
    "        ('scaler', scaler),  # Apply MinMaxScaler\n",
    "        ('classifier', model)  # Apply Logistic Regression with balanced class weights\n",
    "    ])\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=StratifiedKFold(n_splits=5))\n",
    "\n",
    "    # Print the mean accuracy and standard deviation\n",
    "    # print(\"Cross-validation accuracy: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std() * 2))\n",
    "    \n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e9748a1-11b4-41c8-9a83-38d9fbd54c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 24.5 s\n",
      "Wall time: 20.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaler</th>\n",
       "      <th>model</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8834</td>\n",
       "      <td>0.0447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.0389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.0722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.9060</td>\n",
       "      <td>0.0463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.9093</td>\n",
       "      <td>0.0534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>0.0214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.0495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.8525</td>\n",
       "      <td>0.0437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.8525</td>\n",
       "      <td>0.0288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>0.0275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.8541</td>\n",
       "      <td>0.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8557</td>\n",
       "      <td>0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.0589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>0.0738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.9060</td>\n",
       "      <td>0.0463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.9093</td>\n",
       "      <td>0.0534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.0343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.8590</td>\n",
       "      <td>0.0608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.0440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.8525</td>\n",
       "      <td>0.0288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>0.0275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.8541</td>\n",
       "      <td>0.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8541</td>\n",
       "      <td>0.0206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.0409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.8996</td>\n",
       "      <td>0.0647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.9060</td>\n",
       "      <td>0.0463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.9093</td>\n",
       "      <td>0.0534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.8638</td>\n",
       "      <td>0.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>0.0628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.8476</td>\n",
       "      <td>0.0262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.8525</td>\n",
       "      <td>0.0288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>0.0275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.8541</td>\n",
       "      <td>0.0110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            scaler                           model    mean     std\n",
       "0   StandardScaler              LogisticRegression  0.8834  0.0447\n",
       "1   StandardScaler          RandomForestClassifier  0.9044  0.0389\n",
       "2   StandardScaler      GradientBoostingClassifier  0.9044  0.0722\n",
       "3   StandardScaler  HistGradientBoostingClassifier  0.9287  0.0400\n",
       "4   StandardScaler              AdaBoostClassifier  0.9060  0.0463\n",
       "5   StandardScaler                   XGBClassifier  0.9093  0.0534\n",
       "6   StandardScaler                             SVC  0.8849  0.0214\n",
       "7   StandardScaler            KNeighborsClassifier  0.8768  0.0495\n",
       "8   StandardScaler          DecisionTreeClassifier  0.8525  0.0437\n",
       "9   StandardScaler                      GaussianNB  0.8525  0.0288\n",
       "10  StandardScaler      LinearDiscriminantAnalysis  0.8784  0.0275\n",
       "11  StandardScaler   QuadraticDiscriminantAnalysis  0.8541  0.0110\n",
       "12    MinMaxScaler              LogisticRegression  0.8557  0.0240\n",
       "13    MinMaxScaler          RandomForestClassifier  0.9109  0.0589\n",
       "14    MinMaxScaler      GradientBoostingClassifier  0.9061  0.0738\n",
       "15    MinMaxScaler  HistGradientBoostingClassifier  0.9287  0.0400\n",
       "16    MinMaxScaler              AdaBoostClassifier  0.9060  0.0463\n",
       "17    MinMaxScaler                   XGBClassifier  0.9093  0.0534\n",
       "18    MinMaxScaler                             SVC  0.8703  0.0343\n",
       "19    MinMaxScaler            KNeighborsClassifier  0.8590  0.0608\n",
       "20    MinMaxScaler          DecisionTreeClassifier  0.8380  0.0440\n",
       "21    MinMaxScaler                      GaussianNB  0.8525  0.0288\n",
       "22    MinMaxScaler      LinearDiscriminantAnalysis  0.8784  0.0275\n",
       "23    MinMaxScaler   QuadraticDiscriminantAnalysis  0.8541  0.0110\n",
       "24    MaxAbsScaler              LogisticRegression  0.8541  0.0206\n",
       "25    MaxAbsScaler          RandomForestClassifier  0.9109  0.0409\n",
       "26    MaxAbsScaler      GradientBoostingClassifier  0.8996  0.0647\n",
       "27    MaxAbsScaler  HistGradientBoostingClassifier  0.9287  0.0400\n",
       "28    MaxAbsScaler              AdaBoostClassifier  0.9060  0.0463\n",
       "29    MaxAbsScaler                   XGBClassifier  0.9093  0.0534\n",
       "30    MaxAbsScaler                             SVC  0.8638  0.0318\n",
       "31    MaxAbsScaler            KNeighborsClassifier  0.8622  0.0628\n",
       "32    MaxAbsScaler          DecisionTreeClassifier  0.8476  0.0262\n",
       "33    MaxAbsScaler                      GaussianNB  0.8525  0.0288\n",
       "34    MaxAbsScaler      LinearDiscriminantAnalysis  0.8784  0.0275\n",
       "35    MaxAbsScaler   QuadraticDiscriminantAnalysis  0.8541  0.0110"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# generate df report of algorithms' performace\n",
    "output_dict = {\n",
    "    'scaler': [],\n",
    "    'model': [],\n",
    "    'mean': [],\n",
    "    'std': []\n",
    "}\n",
    "\n",
    "for scaler in scalers:\n",
    "    for model in models:\n",
    "        # print(type(scaler).__name__, ' + ', type(model).__name__)\n",
    "        cv_scores = custom_pipeline(scaler, model)\n",
    "        \n",
    "        output_dict['scaler'].append(type(scaler).__name__)\n",
    "        output_dict['model'].append(type(model).__name__)\n",
    "        output_dict['mean'].append( round(cv_scores.mean(),4) )\n",
    "        output_dict['std'].append( round(cv_scores.std() * 2, 4) )\n",
    "\n",
    "df = pd.DataFrame(output_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba4921-7957-4649-ab03-922884796fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
